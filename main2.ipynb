{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing (Cleaning and sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing your datasets\n",
    "directory = '/Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/'  # Replace with the path to your directory\n",
    "\n",
    "# Specify the state to filter by\n",
    "state_filter = \"IL\"  # Use 'IL' if using abbreviations or 'Illinois' for full name\n",
    "\n",
    "# Initialize an empty DataFrame to hold merged data\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through all .csv files in the directory\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Filter rows for Illinois\n",
    "            temp_df = temp_df[temp_df['StateName'] == state_filter]\n",
    "            \n",
    "            # Dynamically select all date columns and relevant metadata columns\n",
    "            metadata_columns = ['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName', 'Metro', 'CountyName']\n",
    "            date_columns = [col for col in temp_df.columns if col.startswith('20')]\n",
    "            \n",
    "            # Keep only metadata and date columns\n",
    "            temp_df = temp_df[metadata_columns + date_columns]\n",
    "            \n",
    "            # Concatenate the current file's data into the merged dataset\n",
    "            merged_data = pd.concat([merged_data, temp_df], ignore_index=True)\n",
    "        except KeyError as e:\n",
    "            print(f\"Skipping {file}: Missing columns {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Reorder columns to place metadata first and dates in descending order\n",
    "metadata_columns = ['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName', 'Metro', 'CountyName']\n",
    "date_columns = sorted([col for col in merged_data.columns if col.startswith('20')], reverse=True)\n",
    "merged_data = merged_data[metadata_columns + date_columns]\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "output_file = os.path.join(directory, \"merged_illinois_data_all_years.csv\")\n",
    "merged_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Merged Illinois data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/merged_illinois_data_all_years.csv'\n",
    "merged_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display dataset information in the terminal\n",
    "print(\"Dataset Information:\")\n",
    "print(merged_data.info())\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst 5 Rows of the Dataset:\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# Show missing values\n",
    "missing_data = merged_data.isnull().sum()\n",
    "print(\"\\nMissing Values in the Dataset:\")\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/ppbrpc751zb9j9ymy8w74shh0000gn/T/ipykernel_39867/2307923766.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_with_enough_pricing[col].fillna(data_with_enough_pricing[col].median(), inplace=True)\n",
      "/var/folders/ns/ppbrpc751zb9j9ymy8w74shh0000gn/T/ipykernel_39867/2307923766.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_with_enough_pricing[col].fillna(data_with_enough_pricing[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to /Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/cleaned_illinois_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/merged_illinois_data_all_years.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Identify date columns dynamically (e.g., columns starting with '20')\n",
    "date_columns = [col for col in data.columns if col.startswith('20')]\n",
    "\n",
    "# Step 2: Define a threshold for the minimum number of non-NaN values required in date columns\n",
    "threshold = int(0.5 * len(date_columns))  # Keep rows with at least 50% non-NaN values in date columns\n",
    "\n",
    "# Step 3: Filter rows with sufficient non-NaN values in date columns\n",
    "data_with_enough_pricing = data[data[date_columns].notna().sum(axis=1) >= threshold]\n",
    "\n",
    "# Step 4: Impute missing values\n",
    "# For numeric columns, fill missing values with the median\n",
    "for col in date_columns:\n",
    "    if data_with_enough_pricing[col].dtype in ['float64', 'int64']:\n",
    "        data_with_enough_pricing[col].fillna(data_with_enough_pricing[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode\n",
    "categorical_columns = data_with_enough_pricing.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    data_with_enough_pricing[col].fillna(data_with_enough_pricing[col].mode()[0], inplace=True)\n",
    "\n",
    "# Step 5: Save the cleaned dataset\n",
    "cleaned_file_path = '/Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/cleaned_illinois_data.csv'\n",
    "data_with_enough_pricing.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to /Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/cleaned_illinois_data_no_empty_columns.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/cleaned_illinois_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the columns to be removed\n",
    "columns_to_remove = ['2025-11-30', '2025-02-28', '2024-12-31']\n",
    "\n",
    "# Drop these columns if they exist in the dataset\n",
    "data = data.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Save the updated dataset\n",
    "output_file_path = '/Users/tarunkatneni/Desktop/Real Estate Chatbot/chatbot/Datasets/cleaned_illinois_data_no_empty_columns.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Updated dataset saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
